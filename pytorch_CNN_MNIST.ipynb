{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_CNN_MNIST.ipynb",
      "provenance": [],
      "mount_file_id": "15P43IcOHuylgGPMUJJZBEvs6mXK34tFQ",
      "authorship_tag": "ABX9TyNvLh1wI1cSuC/O36UzKzW1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArrogantNobody/Pytorch_study/blob/main/pytorch_CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhWvol62blTz"
      },
      "source": [
        "Reference: https://zhuanlan.zhihu.com/p/115866586"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKO4Em-qbjoZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "\n",
        "EPOCH =  3\n",
        "BATCH_SIZE= 50\n",
        "LR= 0.001\n",
        "DOWNLOAD_MINIST = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpdoasQwcS0b"
      },
      "source": [
        "train_data = torchvision.datasets.MNIST(\n",
        "    root = './MINIST',  #数据集的位置\n",
        "    train = True,       #如果为True则为训练集，如果为False则为测试集\n",
        "    transform = torchvision.transforms.ToTensor(),   #将图片转化成取值[0,1]的Tensor用于网络处理\n",
        "    download=DOWNLOAD_MINIST\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vJCbH2tDdQY8",
        "outputId": "81e267e5-14e0-4e26-da93-9d78978528d9"
      },
      "source": [
        "# plot one example\n",
        "print(train_data.train_data.size())\n",
        "print(train_data.train_labels.size())\n",
        "plt.imshow(train_data.train_data[50].numpy(),cmap='Greys')\n",
        "plt.title('%i'%train_data.train_labels[50])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-Jucl6Pd2bk",
        "outputId": "b4a25a0a-a8a5-4d54-a9b3-fc7b3f8b3074"
      },
      "source": [
        "train_loader = Data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root='./MINIST',train=False)\n",
        "\n",
        "#只有在训练的时候才会自动压缩，所以这里采用手动压缩\n",
        "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000]/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
        "test_y = test_data.test_labels[:2000]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYczC8Kyd_ku"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=16,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1\n",
        "            ),                               #维度变换(1,28,28) --> (16,28,28)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)      #维度变换(16,28,28) --> (16,14,14)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=32,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1\n",
        "            ),                               #维度变换(16,14,14) --> (32,14,14)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)      #维度变换(32,14,14) --> (32,7,7)\n",
        "        )\n",
        "        self.output = nn.Linear(32*7*7,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)                  #维度变换(Batch,1,28,28) --> (Batch,16,14,14)\n",
        "        out = self.conv2(out)                #维度变换(Batch,16,14,14) --> (Batch,32,7,7)\n",
        "        out = out.view(out.size(0),-1)       #维度变换(Batch,32,14,14) --> (Batch,32*14*14)||将其展平\n",
        "        out = self.output(out)\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GxW1ZrkeRUT",
        "outputId": "d667da9f-201c-4641-e6ce-cb1c0ae3b489"
      },
      "source": [
        "cnn = CNN()\n",
        "print(cnn)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (output): Linear(in_features=1568, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkkBLLE1fkeQ",
        "outputId": "78f53989-d562-432c-a4d5-9a95e89a76be"
      },
      "source": [
        "for step ,(b_x,b_y) in enumerate(train_loader):\n",
        "  if step == 1:\n",
        "    print(b_x.shape)\n",
        "    print(b_y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 1, 28, 28])\n",
            "torch.Size([50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYsJsunynen",
        "outputId": "efc8cc57-0ed8-4dbf-acb3-d7d54fc38eb8"
      },
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(),lr=LR,)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    for step ,(b_x,b_y) in enumerate(train_loader):\n",
        "        # b_x = x\n",
        "        # b_y = y\n",
        "\n",
        "        output = cnn(b_x)\n",
        "        loss = loss_func(output,b_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step%50 ==0:\n",
        "            test_output = cnn(test_x)\n",
        "            # test_output, last_layer = cnn(test_x)\n",
        "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
        "            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
        "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
        "\n",
        "\n",
        "\n",
        "torch.save(cnn,'cnn_minist.pkl')\n",
        "print('finish training')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | train loss: 2.3177 | test accuracy: 0.10\n",
            "Epoch:  0 | train loss: 0.7940 | test accuracy: 0.80\n",
            "Epoch:  0 | train loss: 0.4326 | test accuracy: 0.83\n",
            "Epoch:  0 | train loss: 0.1859 | test accuracy: 0.88\n",
            "Epoch:  0 | train loss: 0.2715 | test accuracy: 0.91\n",
            "Epoch:  0 | train loss: 0.3549 | test accuracy: 0.92\n",
            "Epoch:  0 | train loss: 0.3742 | test accuracy: 0.92\n",
            "Epoch:  0 | train loss: 0.1514 | test accuracy: 0.94\n",
            "Epoch:  0 | train loss: 0.2356 | test accuracy: 0.95\n",
            "Epoch:  0 | train loss: 0.1791 | test accuracy: 0.95\n",
            "Epoch:  0 | train loss: 0.4489 | test accuracy: 0.95\n",
            "Epoch:  0 | train loss: 0.0680 | test accuracy: 0.96\n",
            "Epoch:  0 | train loss: 0.0728 | test accuracy: 0.96\n",
            "Epoch:  0 | train loss: 0.0927 | test accuracy: 0.96\n",
            "Epoch:  0 | train loss: 0.2426 | test accuracy: 0.96\n",
            "Epoch:  0 | train loss: 0.1256 | test accuracy: 0.96\n",
            "Epoch:  0 | train loss: 0.2662 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.0489 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.0256 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.1737 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.0217 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.1017 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.0470 | test accuracy: 0.97\n",
            "Epoch:  0 | train loss: 0.0391 | test accuracy: 0.96\n",
            "Epoch:  1 | train loss: 0.0488 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0538 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0759 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0360 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0155 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0699 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.1378 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0350 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0807 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0351 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0418 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0500 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0109 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0064 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.1026 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0880 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0469 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0580 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0353 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0957 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0870 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0115 | test accuracy: 0.97\n",
            "Epoch:  1 | train loss: 0.0079 | test accuracy: 0.98\n",
            "Epoch:  1 | train loss: 0.0215 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0233 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0696 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0758 | test accuracy: 0.97\n",
            "Epoch:  2 | train loss: 0.0300 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.2356 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0332 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0784 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.1681 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0013 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0192 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0519 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0356 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0183 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0768 | test accuracy: 0.99\n",
            "Epoch:  2 | train loss: 0.0244 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0144 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.1131 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0044 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0645 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0116 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0034 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0292 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.1115 | test accuracy: 0.98\n",
            "Epoch:  2 | train loss: 0.0613 | test accuracy: 0.98\n",
            "finish training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2ZzlRP904oo",
        "outputId": "d32889ea-532e-4dfa-ec33-da761c254e5b"
      },
      "source": [
        "test_data = torchvision.datasets.MNIST(\n",
        "    root='MINIST',\n",
        "    train=False\n",
        ")\n",
        "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
        "test_y = test_data.test_labels\n",
        "\n",
        "cnn = torch.load('cnn_minist.pkl')\n",
        "\n",
        "test_output = cnn(test_x[:20])\n",
        "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
        "\n",
        "# info = torch.max(test_output,1)[1]\n",
        "# print(test_output)\n",
        "# print(info)\n",
        "\n",
        "print(pred_y, 'prediction number')\n",
        "print(test_y[:20].numpy(), 'real number')\n",
        "\n",
        "\n",
        "test_output1 = cnn(test_x)\n",
        "pred_y1 = torch.max(test_output1, 1)[1].data.numpy()\n",
        "accuracy = float((pred_y1 == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
        "print('accuracy',accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] prediction number\n",
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] real number\n",
            "accuracy 0.9876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QGKXfZjpibpt",
        "outputId": "4c90b3aa-86be-4574-c6c8-61f00069d0e4"
      },
      "source": [
        "        if step%50 == 0:\n",
        "            test_output = cnn(test_x)#torch.Size([2000, 10])\n",
        "            print(test_output)\n",
        "            print(test_output.shape)\n",
        "            pred_y = torch.max(test_output, 1)[1].data.numpy()#len(2000)\n",
        "            print(torch.max(test_output, 1))#返回最大值和最大值所在的索引\n",
        "#             accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
        "#             print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
        "\n",
        "\n",
        "\n",
        "# torch.save(cnn,'cnn_minist.pkl')\n",
        "# print('finish training')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0483, -0.0633, -0.0156,  ...,  0.1496, -0.1009,  0.0780],\n",
            "        [-0.0482, -0.0203,  0.0235,  ...,  0.1198, -0.1104,  0.0485],\n",
            "        [-0.0610,  0.0132,  0.0244,  ...,  0.1150, -0.1026,  0.0460],\n",
            "        ...,\n",
            "        [-0.0511, -0.0200, -0.0053,  ...,  0.1576, -0.0968,  0.0648],\n",
            "        [-0.0447, -0.0034, -0.0153,  ...,  0.1370, -0.0844,  0.0913],\n",
            "        [-0.0238, -0.0445, -0.0026,  ...,  0.1438, -0.0974,  0.0743]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([0.1496, 0.1258, 0.1150,  ..., 0.1576, 0.1370, 0.1438],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 6, 7,  ..., 7, 7, 7]))\n",
            "tensor([[-3.5117, -2.5470, -3.0658,  ...,  4.4235, -0.4685,  0.9456],\n",
            "        [-2.4033, -3.3258,  2.8268,  ..., -7.2900, -0.8266, -4.3965],\n",
            "        [-3.8722,  4.2221, -0.7593,  ..., -0.6063, -0.4975, -0.7155],\n",
            "        ...,\n",
            "        [-2.7087, -0.9251, -1.6565,  ..., -1.6170,  0.0221, -0.8695],\n",
            "        [-3.5132, -1.8833, -2.3162,  ..., -1.2317, -0.3944,  2.2093],\n",
            "        [-2.5783, -3.8923, -3.6080,  ...,  0.2593, -0.6919,  0.9476]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([4.4235, 2.8268, 4.2221,  ..., 2.0096, 2.2093, 0.9476],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 9]))\n",
            "tensor([[ -3.9644,  -7.9196,  -5.3240,  ...,   7.2619,  -1.0909,   1.0275],\n",
            "        [ -2.3700,  -6.5617,   5.1581,  ..., -15.9722,   0.0876, -10.7314],\n",
            "        [ -4.9950,   5.4887,  -0.9626,  ...,  -2.4681,  -1.4968,  -2.3391],\n",
            "        ...,\n",
            "        [ -2.2907,  -3.7852,  -2.9269,  ...,  -4.4426,   0.2183,  -3.6826],\n",
            "        [ -4.1134,  -5.7190,  -4.1225,  ...,  -3.7004,  -0.7056,   2.7303],\n",
            "        [ -2.2612, -10.2357,  -6.4980,  ...,  -1.4603,  -0.6726,  -0.2576]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([7.2619, 5.1581, 5.4887,  ..., 3.8901, 2.7303, 2.8615],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 5]))\n",
            "tensor([[ -5.0422,  -7.9052,  -5.3539,  ...,   9.2965,  -2.0406,   1.6950],\n",
            "        [ -2.4520,  -2.9513,   5.4902,  ..., -16.1098,  -0.5640, -11.5519],\n",
            "        [ -5.1364,   5.9718,  -0.9989,  ...,  -1.6073,  -1.7992,  -2.4163],\n",
            "        ...,\n",
            "        [ -2.7143,  -2.3628,  -3.1431,  ...,  -3.6125,  -0.0164,  -2.7476],\n",
            "        [ -5.2965,  -4.3076,  -3.9440,  ...,  -2.7571,  -0.7762,   4.1100],\n",
            "        [ -3.4887,  -9.5129,  -6.3695,  ...,  -0.9185,  -1.2541,   1.0695]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([9.2965, 5.4902, 5.9718,  ..., 4.5635, 4.1100, 2.0889],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 5]))\n",
            "tensor([[ -4.8622,  -7.5290,  -4.1202,  ...,   8.9660,  -2.8426,   0.7039],\n",
            "        [ -1.9206,  -0.2876,   7.0915,  ..., -17.0960,  -1.1955, -14.5025],\n",
            "        [ -5.0375,   5.4650,  -0.8359,  ...,  -2.2699,  -2.0697,  -3.2228],\n",
            "        ...,\n",
            "        [ -2.9940,  -1.8434,  -2.4042,  ...,  -4.4689,  -0.3041,  -4.4328],\n",
            "        [ -5.8152,  -3.6546,  -3.7493,  ...,  -3.2653,  -0.9727,   3.2948],\n",
            "        [ -3.8849,  -8.6164,  -4.9512,  ...,  -2.4176,  -1.4515,  -0.4420]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([8.9660, 7.0915, 5.4650,  ..., 5.3562, 3.2948, 3.3625],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 5]))\n",
            "tensor([[ -5.8604,  -8.3328,  -4.7882,  ...,  10.2114,  -3.3751,   1.1550],\n",
            "        [ -2.7360,  -0.3303,   6.0912,  ..., -17.5910,  -0.2292, -14.5439],\n",
            "        [ -5.4262,   5.3745,  -1.2431,  ...,  -1.4631,  -1.7433,  -3.5117],\n",
            "        ...,\n",
            "        [ -3.8487,  -2.5164,  -3.4971,  ...,  -3.9924,   0.1873,  -4.1715],\n",
            "        [ -6.3775,  -4.4489,  -5.2545,  ...,  -2.4714,  -1.0057,   4.2395],\n",
            "        [ -4.6911, -10.1409,  -6.1009,  ...,  -2.1391,  -1.2619,   0.0580]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([10.2114,  6.0912,  5.3745,  ...,  5.5144,  4.2395,  3.0652],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 5]))\n",
            "tensor([[ -5.5152,  -6.8481,  -4.5963,  ...,  10.3202,  -4.4050,   1.1561],\n",
            "        [ -1.4948,   0.9682,   7.3992,  ..., -18.5227,  -0.7716, -16.4948],\n",
            "        [ -4.6291,   6.8231,  -0.7560,  ...,  -2.2381,  -2.2129,  -3.9646],\n",
            "        ...,\n",
            "        [ -3.4830,  -1.1566,  -3.5520,  ...,  -4.7458,  -0.3345,  -4.6222],\n",
            "        [ -5.3778,  -3.1024,  -4.4267,  ...,  -2.9992,  -1.8119,   4.2536],\n",
            "        [ -4.2708,  -9.1968,  -5.8792,  ...,  -2.8815,  -2.0299,  -0.2752]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([10.3202,  7.3992,  6.8231,  ...,  4.9819,  4.2536,  4.7810],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 5]))\n",
            "tensor([[ -5.0900,  -8.8904,  -4.9362,  ...,  10.6445,  -4.6882,   1.4276],\n",
            "        [  0.0715,  -1.2071,   7.4946,  ..., -17.3914,  -2.4425, -16.5966],\n",
            "        [ -4.0103,   5.4049,  -1.2321,  ...,  -2.1926,  -2.0441,  -4.0037],\n",
            "        ...,\n",
            "        [ -2.6849,  -3.4198,  -3.7166,  ...,  -4.6298,  -1.2212,  -3.8790],\n",
            "        [ -4.9335,  -5.1852,  -5.6381,  ...,  -3.0635,  -2.2773,   4.6484],\n",
            "        [ -3.9856, -11.4084,  -6.2466,  ...,  -3.0210,  -2.6947,   0.3169]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "torch.Size([2000, 10])\n",
            "torch.return_types.max(\n",
            "values=tensor([10.6445,  7.4946,  5.4049,  ...,  6.6469,  4.6484,  4.4573],\n",
            "       grad_fn=<MaxBackward0>),\n",
            "indices=tensor([7, 2, 1,  ..., 3, 9, 5]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-30243e05a3ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}